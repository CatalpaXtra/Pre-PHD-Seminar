# Outline
5. 梯度问题以及如何缓解
6. 如何高效实现GD & BP？PyTorch 实现？
7. 补充内容（不常用的方法等）
8. 总结

## 梯度消失和梯度爆炸

梯度消失指在反向传播过程中，梯度趋近于零，导致深层网络几乎无法更新；梯度爆炸则相反，梯度变得极大，导致权重更新过大，网络无法收敛。这两个问题的本质都是神经网络层数过深，导致链式求导的连乘效应被放大。
在反向传播中，需要使用链式求导计算损失函数对每层参数的偏导，假设n层的网络，其梯度甲酸简化为
$$\frac{\partial J}{\partial w_i}=\sum_m\cdot \cdot\cdot\sum_l\sum_j\frac{\partial z_m^{(1)}}{\partial w_i}\cdot \cdot\cdot \frac{\partial z_j^{(n)}}{\partial z_l^{(n-1)}}\frac{\partial J}{\partial z_j^{(n)}}$$
其中$z_j^{(k)}$代表第k层第j个节点的激活值。如果连乘项中大部分元素小于1或者大于1，则会导致梯度趋于0或无穷。
缓解这一问题的方法有多种，主要包括：
- 使用ReLU等非饱和（导数几乎不为0）的激活函数
- 恰当的参数初始化
- 使用归一化
- 残差连接
- 梯度剪切
### 激活函数
- Sigmoid激活函数、Tanh激活函数
$$\sigma(x)=\frac{1}{1+e^{-x}}, tanh(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$
输入输出非常大或非常小时，进入“饱和区”，导数几乎为零，梯度指数衰减。
- ReLU激活函数
$$ReLU(x)=max(0,x)$$
$x>0$时，导数恒为1，完全非饱和；$x<0$时，输出和梯度均为0，稀疏激活
### 参数初始化

梯度下降要求在开始时选择合适的参数初始值，这将影响参数收敛的速度；目前参数初始化方法较少，核心思想是打破对称性，使得不同神经元经过不同的权重可以输出不同的激活值。朴素的初始化方法是从$[-\epsilon, \epsilon]$范围的均匀分布或者服从$N(0,\epsilon^2)$的正态分布中随机采样；
而随后研究表明保证**神经网络中每一层输入与输出的方差一致**，可以有效减少梯度问题，出现了 **LeCun 初始化、Xavier 初始化和 He 初始化**。
#### LeCun初始化
该初始化使用于Sigmoid、Tanh等近似线性的激活函数，考虑神经网络某一层输入与输出满足：$$y=\sum_{i=1}^{n_{in}}w_ix_i$$
则经计算有$$Var(y)=\sum_{i=1}^{n_{in}}Var(w_i)Var(x_i)=n_{in}Var(w)Var(x)$$
因此为了满足输入与输出的方差一致，有$$Var(w)=\frac{1}{n_{in}}$$

#### Xavier 初始化
该方法在LeCun 初始化的基础上考虑反向传播的方差，由于反向传播时与权重矩阵转置$W^T$有关，要求$n_{out}Var(w)=1$，由于一般$n_{in}$不等于$n_{out}$，采用调和平均作为权重的方差
$$Var(w)=\frac{2}{n_{in}+n_{out}}$$

#### He 初始化
上述两种初始化方法要求激活函数在线性区工作，对于 ReLU 激活函数失效，He 初始化主要用于解决使用 ReLU 及其变体作为激活函数时梯度消失或梯度爆炸的问题，其核心思想是保证保持每一层输出的方差与输入的方差一致；
假设神经网络的第l层服从下列的转换：
$$a_i^{(l)}=\sum_{j=1}^{M}w_{ij}z_j^{(l-1)}$$
$$z_i^{(l)}=ReLU(a_i^{(l)})$$
其中M代表与第i个神经元连接的上一层神经元个数。
假设第l-1层的激活值$z_j^{(l-1)}$方差为$\lambda^2$，初始化权重均值为0，则根据概率论可以计算得到：
$$
E[a_i^{(l)}]=0 
$$
$$
Var[z_j^{(l)}]=\frac{M}{2}Var[w_{ij}]\lambda^2
$$
$\frac{1}{2}$从 ReLU 的二阶矩中得来，为了保证方差一致，要求$Var[W]=\sqrt{\frac{2}{M}}$ 。如果初始化权重服从正态分布$N(0,\epsilon^2)$，则$\epsilon=\sqrt{\frac{2}{M}}$；如果服从均匀分布$U[-\epsilon,\epsilon]$，则$\epsilon=\sqrt{\frac{6}{M}}$。

#### 正交初始化
对于循环神经网络，梯度消失和梯度爆炸的问题更严重，为此需要采用正交初始化；其思想是将权重矩阵初始化为正交矩阵（极端情况下初始化为单位矩阵），这样可以梯度在长距离传播中保持模长不变，显著提升处理长序列的能力。

#### 疑问
为什么保证输入与输出的方差一致就能稳定梯度？
	损失函数关于权重的梯度和关于输入/输出的梯度相关
为什么 He 初始化不需要类似 Xavier 初始化考虑反向传播？
	$n_{in}$与$n_{out}$区别较小，且大多数层不存在差异，累积差异不会导致指数级变化
能否通过某种初始化方法使得训练中更易收敛到目标函数全局最小值点？

### 归一化

为了稳定梯度，减轻梯度消失、梯度爆炸的影响，除了正确的初始化方法以外，还可以在训练过程中进行归一化；常用的归一化包括：**数据归一化、批次归一化以及层归一化**等。

#### 数据归一化
输入神经网络的数据的不同变量之间往往具有不同的取值范围，这种差异会对梯度下降带来挑战，为此需要在使用数据之前进行归一化预处理，主要将不同变量缩放到统一的取值范围，如$$\hat{x}_{ni}=\frac{x_{ni}-\mu_i}{\sigma_i}$$
其中$n$代表样本序号，$i$代表变量序号，$\mu_i$和$\sigma_i$分别代表所有数据样本中第i个变量的均值和方差。

#### 批次归一化
训练数据不同批次之间存在差异，同样需要将每个批次的数据归一化。
批次归一化与数据归一化类似，但是针对的是神经网络中隐藏层变量，即在每次训练权重更新后，将批次中全部样本对应的隐藏层值进行归一化，同样可以采用上述的正交归一化方法。为了进一步增强隐藏层的表征能力，需要通过额外的参数将隐藏层状态的范围变换到合适的范围，即：
$$
\hat{a}_{ni}=\frac{a_{ni}-\mu_i}{\sqrt{\sigma_i^2+\delta}}
$$
$$
\bar{a}_{ni}=\gamma_i \hat{a}_{ni}+\beta_i
$$
其中$\mu_i,\sigma_i$分别是批次内样本之间隐藏态的均值与方差，$\delta$是小量。
![Normalization](./img/Norm.png)
##### Picture
![](./img/BP%20in%20BN.png)
#### 梯度反向传播如何穿过BN层
不适用BN时，批次中的每个样本独立，求解梯度只需要将各个样本的梯度加和并除以样本数即可
$$d\frac{Loss(minibatch)}{dw_{ij}^{(k)}}=\frac{1}{B}\sum_t\frac{dDiv(Y_t(X_t),d_t(X_t))}{dw_{ij}^{(k)}}$$
其中B代表批次大小，t代表样本号，Div代表每个样本的损失;
经过BN后，同一个批次中每个样本的输出与所有样本的输入均相关，批次中的样本不再独立
$$Loss(minibatch)=\frac{1}{B}\sum_tDiv(Y_t(X_t,\mu_B(X_t,X_{t'\neq t}),\sigma_B(X_t,X_{t'\neq t},\mu_B(X_t,X_{t'\neq t}))),d_t(X_t))$$
![](./img/BP%20in%20BN2.png)
这时梯度反向传播如下（如这里只考虑单个神经元，下表表示批次中样本序号）：
$$\frac{dLoss}{d\hat{z}}=f'(\hat{z})\frac{dLoss}{dy}$$
$$\frac{dLoss}{d\gamma}=u\frac{dLoss}{d\hat{z}}$$
$$\frac{dLoss}{d\beta}=\frac{dLoss}{d\hat{z}}$$
$$\frac{dLoss}{du_i}=\gamma\frac{dLoss}{d\hat{z}_i}$$
![](./img/BP%20in%20BN3.png)
$$\frac{dLoss}{dz_i}=\sum_j\frac{dLoss}{du_j}\frac{du_j}{dz_i}$$
接下来需要计算$du_j/dz_i$，
$$
\begin{equation}
\begin{aligned}
\frac{du_i}{dz_i}&=\frac{\partial u_i}{\partial z_i}+\frac{\partial u_i}{\partial \mu_B}\frac{d\mu_B}{dz_i}+\frac{\partial \mu_i}{\partial \sigma_B^2}\frac{d\sigma_B^2}{dz_i} \\
&=\frac{1}{\sqrt{\sigma_B^2+\epsilon}}+\frac{-1}{B\sqrt{\sigma_B^2+\epsilon}}+\frac{-(z_i-\mu_B)}{2(\sigma_B^2+\epsilon)^{3/2}}\frac{2(z_i-\mu_B)}{B} \\
&=\frac{1}{\sqrt{\sigma_B^2+\epsilon}}+\frac{-1}{B\sqrt{\sigma_B^2+\epsilon}}+\frac{-(z_i-\mu_B)^2}{B(\sigma_B+\epsilon)^{3/2}}
\end{aligned}
\end{equation}
$$
$$
\begin{equation}
\begin{aligned}
\frac{du_j}{dz_i}&=\frac{\partial u_j}{\partial \mu_B}\frac{d \mu_B}{dz_i}+\frac{\partial u_j}{\partial \sigma_B^2}\frac{d \sigma_B^2}{dz_i} \\
&= \frac{-1}{B\sqrt{\sigma_B^2+\epsilon}}+\frac{-(z_i-\mu_B)(z_j-\mu_B)}{B(\sigma_B+\epsilon)^{3/2}}, j\neq i
\end{aligned}
\end{equation}
$$
$$
\begin{equation}
\begin{aligned}
\frac{dLoss}{dz_i}&=\sum_j\frac{dLoss}{du_j}\frac{du_j}{dz_i} \\
&=\frac{1}{\sqrt{\sigma_B^2+\epsilon}}\frac{dLoss}{du_i}-\frac{1}{B\sqrt{\sigma_B^2+\epsilon}}\sum_j\frac{dLoss}{du_j}-\frac{z_i-\mu_B}{B(\sigma_B^2+\epsilon)^{3/2}}\sum_j\frac{dLoss}{du_j}(z_j-\mu_B)
\end{aligned}
\end{equation}
$$


训练过程中可以通过批次内多个样本计算归一化所需要的均值和方差，但是模型推理阶段，一次只输入单个样本，无法直接根据输入进行归一化；为此，需要在训练过程中记录每一个批次归一化的均值以及方差，此外为了增加训练末期归一化设置的权重，采用移动平均：
$$
\bar{\mu}_i^{(\tau)}=\alpha\bar{\mu}_i^{(\tau-1)}+(\alpha-1)\mu_i
$$
$$
\bar{\sigma}_i^{(\tau)}=\alpha\bar{\sigma}_i^{(\tau-1)}+(\alpha-1)\sigma_i
$$
*疑问*：$\gamma,\beta$在什么时候更新？
	前向传播时进行
$$\text{Input} \xrightarrow{\text{Forward}} \underbrace{\text{Conv} \rightarrow \mathbf{BN} \rightarrow \text{ReLU}}_{\text{计算 Loss}} \xrightarrow{\text{Backward}} \underbrace{\text{Calc Gradients}}_{\text{算出 } \Delta W, \Delta \gamma, \Delta \beta} \xrightarrow{\text{Optimizer}} \underbrace{\text{Update Weights}}_{\text{更新 } W, \gamma, \beta}$$
在激活函数前归一化有利于利用激活函数的非线性，防止梯度消失，保证进入激活函数的数据分布稳定。
#### 层归一化
层归一化指对单个批次以及同一隐藏层内不同的神经元之间进行归一化，同样可以引入额外的可学习参数对归一化之后的值进行变换；与批次归一化不同的是，层归一化可以在推理阶段对单个样本进行，因此不需要再训练阶段存储归一化的参数。归一化形式如下：
$$
\hat{a}_{ni}=\frac{a_{ni}-\mu_n}{\sqrt{\sigma_n^2+\delta}}
$$
对于Transformer等架构，更适合采用层归一化，原因如下：
	输入序列的长度不一致，需要padding，会影响BN的效果；
	BN需要批次大小较大，而Transformer架构参数量大导致难以实现较大批次大小；
	训练与推理阶段的数据差异较大，BN训练中得到的归一化统计量不匹配。
层归一化的顺序包括后归一化（Post-Norm）和预归一化（Pre-Norm），训练倾向于 Pre-Norm，即先进归一化，之后进行注意力等计算。

1. 后归一化
LN 位于残差加法之后：
$$x_{l+1}=LayerNorm(x_l+F_l(x_l))$$
其中$F(x_l)$代表自注意力或前馈网络子层；
后归一化相对更难训练，需要严苛的学习率预热。
$$\frac{\partial \mathcal{L}}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial x_{l+1}} \cdot \underbrace{\frac{\partial \text{LayerNorm}(y_l)}{\partial y_l}}_{\text{① LN 的雅可比矩阵}} \cdot \underbrace{\left( I + \frac{\partial F_l(x_l)}{\partial x_l} \right)}_{\text{② 残差结构的导数}}$$
$$\frac{\partial \text{LayerNorm}}{\partial y_l} \approx \frac{\gamma}{\sigma_l} \cdot (\dots)$$
第$l$层梯度来自于下一层梯度乘上系数，那么层数加深，系数如果偏离1，梯度会指数缩小或放大，导致梯度消失或爆炸。
2. 预归一化
LN 位于子层计算之前，而残差连接直接跳过子层和 LN：
$$x_{l+1}=x_{l}+F_l(LayerNorm(x_l))$$
$$\frac{\partial \mathcal{L}}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial x_{l+1}} \cdot \left( I + \frac{\partial F_l}{\partial \text{LN}} \frac{\partial \text{LN}}{\partial x_l} \right)$$
假设每一层更新$F_l$方差近似为1，那么随着层数增加，$x_L$的方差会线性累积，深层网络中$\frac{\partial \text{LN}}{\partial x_l}\approx \frac{\gamma}{\sigma_L}$ 会很小，梯度更新主要来源于恒等映射，可能导致“表征崩塌”。
3. DeepNorm
$$x_{l+1} = \text{LayerNorm}(\alpha \cdot x_l + f_l(x_l, \theta_l))$$
引入系数$\alpha > 1$放大主干信号$x_l$，$f_l(x_l,\theta_l)$保持不变或变小，整体采用后归一化结构，避免表征崩塌。
工程实现通过缩放初始化时的权重，即
$$W_{int}\leftarrow \frac{W_{std}}{\beta}$$
对于N层的Transformer，参数一般取为$\alpha=(2N)^{1/4},\beta=(8N)^{1/4}$。

## 如何高效进行GD & BP？

**动态计算图+自动微分+优化器**
### 计算图
#### 定义
计算图是一个有向图$G=(V,E)$，用于表示数学表达式的运算过程。
![计算图示例](./img/Com_diagram.png)
1. 节点
在通用的计算图定义中，节点通常代表数学运算（Operations, Ops）或变量（Variables）。
- **运算节点**：代表函数变换，如矩阵乘法（MatMul）、加法（Add）、激活函数（ReLU, Sigmoid）等。
- **变量节点**：代表承载数据的实体，如标量、向量、矩阵或张量（Tensor）。
2. 边
 图中的有向边 $u \to v$ 表示节点 $u$ 的输出是节点 $v$ 的输入。这种连接关系确立了两个核心属性：
- **数据依赖（Data Dependency）**：为了计算节点 $v$ 的值，必须先计算节点 $u$ 的值。这隐含了拓扑排序（Topological Sort）的需求，决定了前向传播（Forward Pass）的执行顺序。
- **梯度传播路径（Gradient Flow Path）**：在反向传播（Backward Pass）中，梯度沿着边的反方向流动。边上的权重或雅可比矩阵（Jacobian Matrix）定义了局部导数，通过链式法则在图中累积。
#### 静态图与动态图
1. 静态图
静态图指先构建完整的计算图，然后执行数值计算，典型实现为 TensorFlow 1.x。该模式由于在代码执行前已知图结构，可以进行全局优化，但是同样会导致调试困难。
2. 动态图
动态图指计算图在代码运行过程中同步构建，每次前向传播均动态生成一个计算图。这将带来更高的灵活性，但是存在一定的运行资源要求。

#### PyTorch 动态计算图
**Tensor 与 requires_grad**：在 PyTorch 中，计算图的基本组成单元是张量对象 (`torch.Tensor`) 和对张量的操作。通常只有 **叶子张量（Leaf Tensor)** 会保存梯度，即由用户直接创建的、`requires_grad=True` 的张量（不依赖其他张量生成）被视为计算图的叶节点，而由运算得到的中间张量则是非叶节点。在创建 `Tensor` 时通过参数 `requires_grad=True` 可以开启对该张量的梯度追踪，此时对它的任何后续运算都会被记录在计算图中。如果一个运算的**任意输入**设置了 `requires_grad=True`，则其输出张量也将被标记为需要梯度，这样输出会加入计算图并能够参与反向传播。反之，如果所有输入不需要梯度，则计算会在“图之外”进行，输出也不包含梯度信息。下面的代码示例演示了张量的梯度属性和计算图的构建过程
```#python
import torch

# 创建一个 2x2 张量，开启梯度追踪
x = torch.ones(2, 2, requires_grad=True)
print(x)               # 打印张量的值
print(x.grad_fn)       # 因为 x 是用户创建的叶子张量，grad_fn 应为 None

# 对张量进行加法运算
y = x + 2
print(y)               # y 是计算得到的张量
print(y.grad_fn)       # y 有对应的 grad_fn, 表明它由加法操作产生
```
**grad_fn 属性：** 正如上述输出所示，每个由操作产生的张量都有一个 `grad_fn` 属性，指向一个表示其生成方式的**函数对象**；需要注意，对于**叶子张量**来说，`grad_fn` 为 None，因为它并非由其他张量运算而来
**backward() 调用：** 构建计算图的目的在于后向自动求导。当我们得到标量损失张量（计算图的输出）后，可以调用其 `.backward()` 方法来启动反向传播。此时 Autograd 将从该张量的 `grad_fn` 开始，沿计算图**反向遍历**各个节点，计算每个节点对其输入的梯度，并将结果累加到各输入张量的 `.grad` 属性中。需要注意，如果目标张量不是标量（例如包含多个元素），则调用 `backward()` 需要传入一个与之同形的梯度张量，表示最终输出相对于自身的梯度（通常取全1向量）。否则也可以先将多元素张量缩并为标量（例如求和或取平均）再反向传播。
**detach() 操作：** 在某些情况下，我们需要从计算图中**隔离**出某些张量，使其在后续计算中不追踪梯度。PyTorch 提供了 `Tensor.detach()` 方法来返回一个**新张量**，该张量指向原始数据内存但被从当前计算图中分离出来——新张量的 `requires_grad=False`，且没有 `grad_fn`
### 自动微分
### 自动微分的必要性
使用梯度反向传播更新参数时，需要计算损失函数关于参数的梯度值，共有四种方式计算。
- 第一种方法是提前计算出反向传播中梯度的表达式，然后在代码中显式定义并计算，该方法依赖人力计算梯度表达式，对于目前的深层网络不适用。
- 第二种方法称为符号微分，使用计算机代数等方法自动计算梯度的解析表达式，该方法解决了人力的问题，但是符号微分得到的解析式往往很复杂，同时存在重复计算浪费资源的问题；此外，符号微分要求需要被微分的表达式具有封闭形式（即不包括无穷级数、极限、积分或迭代求解过程）。
- 第三种方法采用有限差分对梯度进行数值计算，但是该方法存在计算精度不足问题，由于计算单个参数的梯度均需要一次前向传播，所以对于参数量大的网络难以规模化应用；但是该方法不依赖反向传播过程，可以用于检验反向传播算法的正确性。
- 第四种方法是自动微分，包括前向自动微分和反向自动微分两种，其依赖计算图逐步计算梯度值，是目前深度学习的主流算法。

#### 数值微分
数值微分方法基于有限差分计算梯度，通过对权重进行微扰，计算目标函数的变化近似求解梯度，公式如下：
$$
\frac{\partial J_n}{\partial w_{ji}}=\frac{J_n(w_{ji}+\epsilon)-J_n(w_{ji})}{\epsilon}+O(\epsilon)
$$
其中$\epsilon$为小量，误差与$\epsilon$大小成正比；此外可以通过采用中心差分进一步提高精度至$O(\epsilon^2)$
$$
\frac{\partial J_n}{\partial w_{ji}}=\frac{J_n(w_{ji}+\epsilon)-J_n(w_{ji}-\epsilon)}{2\epsilon}+O(\epsilon^2)
$$
减小$\epsilon$可以有效提高精度，直至达到计算机数值极限。
该方法只需要正向传播计算损失函数，对于每个权重的梯度计算，需要$O(W)$步，因此整个网络的权重计算代价为$O(W^2)$。
但是数值微分的结果可以用来和自动微分等其他依赖反向传播的结果对比，用于检查代码正确性。

#### 反向自动微分
计算图构建之后，假设中间变量为$v_i$，输出函数为$f$，则定义$\bar{v}_i=\frac{\partial f}{\partial v_i}$ ，因此根据链式法则有
$$\bar{v}_i=\frac{\partial f}{\partial v_i}=\sum_{j\in ch(i)}\frac{\partial f}{\partial v_j}\frac{\partial v_j}{\partial v_i}=\sum_{j\in ch(i)}\bar{v}_j\frac{\partial v_j}{\partial v_i}$$
因此沿着计算图反向传播，即可计算出输出值关于输入值的微分，每个输出值对应一次传播路径，对于$M$个输出变量，只需要$M$条反向传播路径，即可得到整个雅可比矩阵。
但是由于反向传播计算过程需要使用正向传播的中间变量值，因此需要存储正向传播的中间变量值，有一定的内存要求。
#### 正向自动微分
正向自动微分与反向类似，假设中间变量$v_i$，输入变量为$x_1$，输出函数$f$，不同的是定义中间变量关于输入的微分$\dot{v}_i=\frac{\partial v_i}{\partial x_1}$ ，同样根据链式求导有
$$\dot{v}_i=\frac{\partial v_i}{\partial x_1}=\sum_{j\in pa(i)}\frac{\partial v_j}{\partial x_1}\frac{\partial v_i}{\partial v_j}=\sum_{j\in pa(i)}\dot{v}_j\frac{\partial v_i}{\partial v_j}$$
其中$pa(i)$代表i节点的父节点，即指向i节点。
沿着计算图正向传播过程中，可以同步的计算$\dot{v}_i$值，最终得到$\dot{f}$值；输出关于每个输入变量的微分均需要一次独立正向传播路径，即假设有N个输入变量，计算关于第i个输入变量的微分，需要设置$\dot{x}_i=1,\dot{x}_j=0(j\neq i)$，进而需要N次正向传播才能够得到整个雅各比矩阵，计算资源要求高。

#### 实际应用
一般情况下，输入变量远多于输出变量(即$N>>M$，输出一般只有一个损失函数值)，正向自动微分尽管能够同步计算中间状态值与微分，但需要过多的正向传播过程，计算资源要求过高；因此在实际应用中一般采用反向自动微分。

但是前向自动微分在某些场景也具有优势，比如计算雅可比矩阵和向量的积
$$
\mathbf{J} = 
\begin{bmatrix}
    \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_D} \\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_K}{\partial x_1} & \cdots & \frac{\partial f_K}{\partial x_D}
\end{bmatrix}
\begin{bmatrix}
    r_1 \\
    \vdots \\
    r_D
\end{bmatrix}
$$
即可通过设置$\dot{\textbf{x}}=\textbf{r}$，进行一次前向传播计算得到。

混合自动微分可以用于计算海森矩阵与向量的乘积$\textbf{Hv}$，首先设置$\dot{\textbf{x}}=\textbf{v}$并进行一次正向传播得到$y = (\nabla f(x))\textbf{v}$（y为标量），再对于上述计算过程进行反向传播，得到$\nabla_x (\nabla f(x) \textbf{v})=\nabla^2 f \textbf{v}=\textbf{Hv}$ ， 总的时间复杂度为$O(W)$。

## 补充内容
### 并行与分布式训练（Parallel and Distributed Training）
- 并行模式：
	数据并行：不同设备处理不同数据
	模型并行：不同设备处理模型不同部分
- 梯度聚合（数据并行）：
	同步更新：全部节点计算结束后，统一更新参数
	异步更新：各个节点独立计算独立更新

数据并行+同步更新=超大Batch=收敛性差

#### 准确率和速度的权衡（trade-offs）
1.线性缩放规则 (Linear Scaling Rule)
	当 Batch Size 增大 k 倍时，将学习率 η 也增大 k 倍
2.专用优化器 (LARS / LAMB)
	根据每一层的权重范数和梯度范数比值，动态调整该层的学习率
3.改用模型并行
4.本地更新：
	每个GPU独立更新若干步后，同步各设备
	减少通信次数

#### 专用优化器
##### LARS
基于SGD，
对于网络中的第 $l$ 层，参数为 $w_l$，梯度为 $\nabla L(w_l)$。LARS 计算一个**局部学习率乘子（Local Learning Rate Multiplier）**，也称为信任比率 $\lambda_l$：
$$\lambda_l = \eta \times \frac{\| w_l \|}{\| \nabla L(w_l) \| + \beta \| w_l \|}$$
- $\| w_l \|$：该层权重的 L2 范数。
- $\| \nabla L(w_l) \|$：该层梯度的 L2 范数。
- $\beta$：权重衰减系数（Weight Decay），分母加上它是为了防止梯度过大导致步长失控。
**更新规则**：
$$\Delta w_l = \gamma \cdot \lambda_l \cdot \nabla L(w_l)$$
**直观解释：**
- 如果某一层权重很大，但梯度很小 $\rightarrow$ $\lambda_l$ 变大 $\rightarrow$ 放心大胆地更新。
- 如果某一层权重很小，但梯度剧烈 $\rightarrow$ $\lambda_l$ 变小 $\rightarrow$ 小心翼翼地更新，防止把原本很小的权重直接“震飞”。
##### LAMB(Layer-wise Adaptive Moments optimizer for Batch training)
LAMB 首先执行标准的 AdamW 步骤来计算“更新方向” $r_t$：
1. 计算一阶动量 $m_t$ 和二阶动量 $v_t$（同 Adam）。
$$\mathbf{g_t}=\nabla E(\mathbf{w}_t)$$
$$\mathbf{m}_t = \beta_1 \mathbf{m}_{t-1} + (1 - \beta_1) \mathbf{g}_t$$
$$\mathbf{v}_t = \beta_2 \mathbf{v}_{t-1} + (1 - \beta_2) \mathbf{g}_t^2$$
2. 计算无缩放的更新方向：$r_t = \frac{m_t}{\sqrt{v_t} + \epsilon} + \lambda w_t$ （Adam 的修正方向 + Weight Decay）。
关键的一步： 计算这一层的信任比率 $\phi_t$：
$$\phi_t = \frac{\| w_t \|}{\| r_t \|}$$
**更新规则**
$$w_{t+1} = w_t - \eta \cdot \phi_t \cdot r_t$$

### 优化问题二阶方法
详细理论推导见[[Convergence]]
#### 牛顿二阶方法
对于一般的目标函数，采用泰勒级数展开：
$$E(\textbf{w})\approx E(\textbf{w}^{(k)})+\nabla_{\textbf{w}}E(\textbf{w}^{(k)})(\textbf{w}-\textbf{w}^{(k)})+\frac{1}{2}(\textbf{w}-\textbf{w}^{(k)})^TH_E(\textbf{w}^{(k)})(\textbf{w}-\textbf{w}^{(k)})$$
对左边进行正交化之后得到参数更新公式
$$\textbf{w}^{(k+1)}=\textbf{w}^{(k)}-\eta\textbf{H}_E(\textbf{w}^{(k)})^{-1}\nabla_{\textbf{w}}E(w^{(k)})^T,\eta=1<2$$

该坐标变换相当于对Hessian矩阵进行特征分解$\mathbf{H}=\mathbf{U^T\Lambda  U}$，使用特征向量组成的矩阵进行坐标系旋转$\mathbf{\hat{w}}=\mathbf{Uw}$ ，使用特征值$\lambda_i$进行缩放坐标轴。

牛顿方法等价于在$\textbf{w}^{(k)}$附近使用二次型拟合，随后对该二次型采用最优步长优化至最小值。
![[Pasted image 20251222204302.png]]
**缺点：
	海森矩阵纬度高，求逆计算复杂度高
	在非凸区域 Hessian 可能非正定，导致算法发散
	学习率$\eta<2$固定，容易陷入局部最小值**

#### 拟牛顿法
避免直接求解海森矩阵的逆，近似求解。
- BFGS方法
迭代更新Hessian 矩阵的逆矩阵$D^{(k)}=\mathbf{H}_E(w^{k})^{-1}$：
$$\mathbf{D}^{(k+1)} = \left( \mathbf{I} - \rho_k \mathbf{s}^{(k)} (\mathbf{y}^{(k)})^T \right) \mathbf{D}^{(k)} \left( \mathbf{I} - \rho_k \mathbf{y}^{(k)} (\mathbf{s}^{(k)})^T \right) + \rho_k \mathbf{s}^{(k)} (\mathbf{s}^{(k)})^T$$
$$\mathbf{y}^{(k)} = \nabla_{\mathbf{w}} E(\mathbf{w}^{(k+1)})^T - \nabla_{\mathbf{w}} E(\mathbf{w}^{(k)})^T,
\mathbf{s}^{(k)} = \mathbf{w}^{(k+1)} - \mathbf{w}^{(k)},
\rho_k = \frac{1}{(\mathbf{y}^{(k)})^T \mathbf{s}^{(k)}}$$
- L-BFGS方法
高效内存使用下的BFGS方法。
- QuickProp 方法
假设各个参数独立，有限差分近似海森矩阵：
$$\mathbf{y}^{(k)} = \nabla_{\mathbf{w}} E(\mathbf{w}^{(k+1)})^T - \nabla_{\mathbf{w}} E(\mathbf{w}^{(k)})^T,
\mathbf{s}^{(k)} = \mathbf{w}^{(k+1)} - \mathbf{w}^{(k)},
\rho_k = \frac{1}{(\mathbf{y}^{(k)})^T \mathbf{s}^{(k)}}$$
### SGD Noise
在SGD 过程中，除了mini-batch 导致的噪声，人为引入额外噪声
有利于跳出局部极小值，提升模型泛化能力
Adam 等自适应方法，平均历史梯度平滑了噪声
- 随机梯度朗之万动力学 (SGLD)
在 SGD 更新公式中加入特定的缩放噪声项
$$\Delta w^{k+1} = -\frac{\eta_k}{2} \nabla E(w^k) + \underbrace{\sqrt{\eta_k} \cdot N(0, I)}_{\textbf{Gaussian Noise}}$$