## Introduction
Chapter 1
Gradient Desent && Backpropagation

## GD in Mathematical Optimization
### 问题定义
*   **目标**：寻找目标函数 $ J(\theta) $ 的极小值点（通常为局部极小值）及其对应的参数 $\theta^*$，即 $\theta^* = \arg\min_{\theta} J(\theta)$

![alt text](img/math.png)

*   **挑战**：目标函数通常具有高维、非凸、非线性的复杂特性，且可能伴有噪声。导致无法通过直接解析（如令导数为零）的方法求得全局最优解，必须依赖迭代数值优化算法。

---

### 梯度下降（SGD, Stochastic Gradient Descent）
基于一阶导数的经典迭代优化算法。
**核心思想**：沿着目标函数在当前点的梯度反方向（即函数值下降最快的方向）逐步调整参数，从而逼近函数的局部极小值。

**算法过程**：
1.  **初始化**：随机选择或指定一组参数的初始值 $\theta_0$，设定学习率 $\alpha$（步长）和迭代终止条件（如最大迭代次数或梯度范数阈值）。
2.  **迭代更新**：对于第 $k$ 次迭代（$k = 0, 1, 2, ...$）：
    *   **计算梯度**：计算目标函数在当前参数 $\theta_k$ 处的梯度 $\nabla J(\theta_k)$。
    *   **更新参数**：沿梯度反方向更新参数：$\theta_{k+1} = \theta_k - \alpha \cdot \nabla J(\theta_k)$。
    *   **检查收敛**：判断是否满足终止条件（如梯度足够小、$J(\theta)$ 变化不明显或达到最大迭代次数）。若满足，则停止迭代，输出当前 $\theta_{k+1}$ 作为近似解；否则，继续进行下一轮迭代。

**相关挑战**：
*   **学习率选择**：固定学习率难以适应训练全过程。
*   **地形问题**：不同参数方向梯度尺度差异巨大（病态条件数，如沟壑/平原），导致收敛缓慢。
*   **局部最优与鞍点问题**：在高维空间，鞍点比局部极值点更常见。

---

### 算法演进
1.  **引入动量（Momentum）**
    *   **核心思想**：模拟物理中的动量，当前更新方向不仅取决于当前梯度，还累积历史梯度的指数加权平均。
    *   **作用**：
        *   **加速收敛**：在梯度方向一致的维度上加速。
        *   **抑制震荡**：通过动量平滑掉不一致的梯度噪声，帮助穿越狭窄的“沟壑”。

2.  **自适应学习率（Per-parameter Learning Rate）**
    *   **核心思想**：为网络中**每一个参数**单独调整学习率。根据该参数的历史梯度信息，自动放大或缩小其更新步长。
    *   **代表算法RMSProp**：改进AdaGrad，引入衰减系数，只关注近期梯度历史，解决了学习率过早衰减的问题。

---

### 主流
1. **RMSProp** (Root Mean Square Propagation)
    引入衰减系数，**只关注近期梯度历史**，淡化遥远过去梯度的影响。从而解决了学习率单调下降的问题，使训练能够持续进行。
    1.  **计算梯度平方的指数移动平均**：
        $$
        E[g^2]_t = \rho \cdot E[g^2]_{t-1} + (1 - \rho) \cdot g_t \odot g_t
        $$
        不累积全部历史梯度平方和，而是计算一个**指数衰减的移动平均**。
        *   $ \rho $ 是衰减率（通常设为0.9）
        *   $ E[g^2]_t $ 可以理解为**近期梯度平方的期望估计**，赋予算法“短期记忆”。
    2.  **参数更新**：
        $$
        \theta_{t} = \theta_{t-1} - \frac{\eta}{\sqrt{E[g^2]_t} + \epsilon} \odot g_t
        $$
        **自适应机制**：对于某个参数，如果其历史梯度 $ \sqrt{E[g^2]_t}t $ 很大（更新频繁或幅度大），那么其对应的缩放因子就会变小，从而**减小该参数的实际学习步长**。反之，对于历史梯度小的稀疏参数，其有效学习率相对较大。

2. **Adam** (Adaptive Moment Estimation)
    **同时结合了动量（Momentum）和RMSProp的思想**，通过自适应调整每个参数的学习率来加速收敛并提升训练稳定性。
    1.  **计算梯度的一阶矩估计（动量项）**：
        $$
        m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
        $$
        其中
        - $ g_t $ 是当前时间步 $ t $ 的梯度
        - $ m_{t-1} $ 是上一时间步的动量向量
        - $ \beta_1 $是衰减率（通常=0.9）

        相当于对梯度做**指数移动平均**，保留历史梯度方向的信息
    2.  **计算梯度的二阶矩估计（自适应项）**：
        $$
        v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
        $$
        其中
        - $ g_t^2 $ 表示梯度的逐元素平方
        - $ \beta_2 $是另一个衰减率（通常=0.999）
        
        相当于对梯度平方做**指数移动平均**，反映**各参数历史梯度量级的变化幅度**。量级（对应 $ v_t $）大的参数通常意味着其更新不稳定或梯度本身较大，后续作自适应调节。
    3.  **偏差修正**：
        由于 $ m_t $ 和 $ v_t $ 在初始时间步（$ t $ 较小时）是从零向量开始估计的，会偏向于零。Adam引入时间步相关的修正来抵消初始化偏差，有助于训练早期稳定更新。
        $$
        \hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \ \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
        $$
        随着 $ t $ 增大，$ \beta^t $ 趋近于0
    4.  **参数更新**：
        $$
        \theta_t = \theta_{t-1} - \eta \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
        $$
        其中
        - $ \eta $ 是初始学习率
        - $ \epsilon $ 极小（通常≈$ 10^{-8} $），防止除以零
        - $ \hat{m}_t $ 提供**动量方向**
        - $ \sqrt{\hat{v}_t} $ 起到**逐参数自适应缩放学习率**的作用：对于历史梯度平方和较大的参数，其步长会被缩小；反之则步长相对较大

3.  **AdamW** (Adam with Weight Decay)
    **将权重衰减（Weight Decay，即L2正则化项）从梯度计算中解耦出来**，直接、独立地应用于参数更新，而非作为损失函数的一部分影响梯度。在标准Adam优化器基础上的一个重要改进。
    1.  **计算梯度的一阶矩估计（动量项）**：与Adam完全相同
    2.  **计算梯度的二阶矩估计（自适应项）**：与Adam完全相同
    3.  **偏差修正**：相同
    4.  **参数更新**：
        $$
        \theta_{t} = \theta_{t-1} - \eta_t \left( \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \color{blue}{+ \lambda \theta_{t-1}} \right)
        $$
        由两部分组成：
        -   **自适应梯度更新**：$ \eta_t \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $，这部分与Adam一致
        *   **解耦的权重衰减**：$ \color{blue}{\eta_t \lambda \theta_{t-1}} $，这是一个**直接、与梯度无关的收缩项**。它独立于自适应学习率机制，以一个固定的速率 $ \lambda $（权重衰减系数）将参数向零收缩。**以实现正则化**

    **与标准Adam（耦合权重衰减）的对比**：
    - 在标准Adam中，权重衰减通常被加入损失函数，即梯度 $ g_t $ 中已经包含了 $ \lambda \theta_{t-1} $ 项。
    - 意味着**权重衰减的效果会被自适应学习率（$ \sqrt{\hat{v}_t} $）所缩放**，导致对于梯度较大的参数，其正则化强度反而被削弱。
    - AdamW通过解耦，确保了**权重衰减的效果是稳定且一致的**，不受参数梯度历史量级的影响。

    **优势总结**：
    - AdamW保留了Adam的所有优点——**动量带来的方向稳定性和自适应学习率带来的各参数步长灵活性**。
    - 通过**解耦权重衰减**，提供了更纯粹、更可控的正则化。使模型在追求高性能的同时，能更好地避免过拟合。
    - 在大容量模型（如Transformer）的训练中，AdamW已成为获得更优泛化能力的首选优化器。


---



## Backpropagation && GD in Neraul Network
### 神经网络本质
1. **Neraul Network Intro**
    * 由大量相互连接的神经元组成的计算模型，通过层层非线性变换，能够学习输入与输出之间复杂的映射关系。
2.  **问题定义**
    *   **目标**：寻找一组最优权重参数，最小化损失函数，使模型预测最准确。
    *   **挑战**：高维、非凸、非线性的复杂优化问题，无法直接解析求解。
3.  **核心方法**
    *   **反向传播（Backpropagation）**：计算梯度。高效、精确地计算损失函数对百万乃至亿级权重的梯度（导数）。
    *   **梯度下降（Gradient Descent）**：更新模型参数。利用梯度信息，迭代地更新权重，引导模型向最优解移动。

---

### 模型损失函数 && 反向传播
**损失函数**：衡量模型预测与真实目标之间差异的标量函数，训练的目标就是最小化损失函数。  
如用于回归的均方误差（MSE）；用于分类的交叉熵损失（Cross-Entropy）

**反向传播核心步骤**：
1.  **前向传播**：输入数据通过网络层层传递，直至输出层得到预测值。此过程计算并保存每一层的中间激活值，同时计算最终的损失函数值。
2.  **反向传播**：从输出层开始，计算损失函数对输出层输入的梯度，然后利用链式法则，逐层向后计算损失函数对每一层权重和输入的梯度。这个过程中，中间结果的梯度可以被复用，大大提高了计算效率。最终，我们得到损失函数关于网络中所有权重参数的梯度向量 $\nabla_{\theta} L(\theta)$，其中 $\theta$ 代表全部参数。

---

### 反向传播Demo
TODO
![alt text](img/demo.png)

---

### 梯度下降算法 with Batch Size
梯度下降的核心迭代公式为：
$$
\theta_{t+1} = \theta_t - \eta \cdot \nabla_{\theta} L(\theta_t)
$$
其中 $\eta$ 是学习率，控制更新的步长。根据计算梯度时所用数据量的不同，梯度下降主要有三种变体，它们在效率、稳定性和泛化能力上各有权衡：

1.  **（纯）随机梯度下降（SGD）**
    *   **原理**：每次迭代随机使用**一个样本**计算梯度并立即更新。
    *   **优点**：
        *   **速度极快**，更新频率高。
        *   **引入的噪声有助于跳出局部最优和尖锐极小点**，可能找到泛化更好的平坦解。
    *   **缺点**：**更新方向震荡剧烈**，收敛过程不稳定，难以精细调优。

2.  **批量梯度下降（Batch GD）**
    *   **原理**：每次迭代使用**全部训练数据**计算精确梯度。
    *   **优点**：梯度方向稳定，理论收敛性好。
    *   **致命缺点**：
        *   **计算成本极高**：每步更新都需遍历全量数据，内存和计算无法承受。
        *   **易陷入局部最优**：更新方向过于“确定”，缺乏探索能力。
        *   **无法在线学习**。

3.  **小批量随机梯度下降（Mini-batch SGD）**
    *   **原理**：将数据划分为若干**小批量（Batch）**，每次使用一个批次的样本估计梯度。
    *   **为什么是“估计”？** 小批量梯度是全量数据真实梯度的**无偏但带噪声的估计**。
    *   **“小批量”的平衡艺术**：
        *   **效率**：相比全批量，计算开销小，能充分利用GPU并行计算。
        *   **稳定性**：相比单样本，梯度估计更准确，更新路径更平滑。
        *   **泛化性**：相比全批量，适度的噪声起到正则化作用，防止过拟合。

---



# TODO
## How to choose optimizer


## Future Work
1.  **更先进的优化器**
2.  **二阶优化方法**：探索利用损失函数的二阶导数（海森矩阵或其近似）信息的优化方法，如自然梯度下降、KFAC等，以期获得更优的收敛特性，尽管其计算和存储成本通常更高。
3.  **优化理论的新理解**：深入研究为什么带噪声的SGD（以及小批量SGD）往往比全批量梯度下降找到的解泛化能力更好，探索损失函数几何景观（如平坦极小值）与泛化性能之间的联系。
4.  **大规模分布式训练**：针对超大模型和数据集，研究高效的分布式优化算法，如数据并行、模型并行、流水线并行以及它们的混合策略，以解决单机资源瓶颈。
5.  **训练稳定性与加速**：研究梯度裁剪、学习率预热、动态批次大小等技术，以稳定超大规模模型的训练过程，并进一步提升训练效率。
6.  **元学习与自动化优化**：模型如何学会如何优化自身（学习优化器），或使用自动化机器学习（AutoML）技术来动态调整优化超参数（如学习率调度）。


## Practice in LLM
### LLM训练的本质
1. **LLM简介**
大型语言模型（Large Language Model, LLM）是一种基于Transformer架构构建的、参数量极其庞大（通常为数十亿至数万亿）的深度学习模型。其核心目标是通过在海量无标注文本数据上进行自监督预训练，学习人类语言的通用表示、语法规则、世界知识以及逻辑推理能力。LLM通过预测文本序列中的下一个词（或词元）这一基础任务，掌握了语言的生成与理解能力，并能够通过指令微调、对齐等技术，泛化到多种下游任务，展现出强大的通用人工智能潜力。

2. **问题定义**
    *   **目标**：在给定海量文本数据集 $ \mathcal{D} $ 上，寻找一组最优的模型参数 $ \theta $，最小化基于自监督任务（如语言建模）的损失函数 $ L(\theta; \mathcal{D}) $，使模型能够准确预测或生成符合语言规律和上下文逻辑的文本。
    *   **挑战**：
        1.  **前所未有的规模**：参数量（$ \|\theta\| $）达到 $10^9 \sim 10^{12}$ 级别，导致优化空间维度极高，对梯度计算（反向传播）和参数更新的存储、通信带来极限压力。
        2.  **海量数据**：训练数据可达万亿词元量级，遍历一次（一个epoch）的计算成本极高，要求优化算法在极少的数据遍历次数内高效收敛。
        3.  **训练不稳定性**：在超大规模模型训练中，梯度爆炸/消失、损失值突变（loss spike）、数值溢出等问题更为常见且危害巨大。
        4.  **泛化与记忆的平衡**：模型容量极大，极易完全记忆训练数据而导致过拟合，需要在优化过程中引入有效的隐式或显式正则化，促使模型学习可泛化的模式而非噪声。
        5.  **计算资源瓶颈**：单卡内存无法容纳整个模型和优化器状态，必须依赖复杂的分布式并行训练策略（如数据并行、模型并行、流水线并行），这使得优化算法的设计与系统工程深度耦合。

3. **核心方法论的延续与演进**
LLM的训练本质上仍然是遵循“反向传播提供梯度，梯度下降指导更新”的范式，但面对上述挑战，其具体实现发生了深刻演进：
    *   **反向传播（Backpropagation）**：**基础引擎依然核心**。其高效计算梯度的能力是训练任何深度网络的基石。在LLM中，反向传播的计算图因Transformer的复杂结构（多头注意力、前馈网络、残差连接、层归一化）而变得巨大，但其链式法则的本质未变。核心挑战在于如何**分布式地、高效地**完成跨数千张GPU的反向传播计算。
    *   **梯度下降（Gradient Descent）**：**导航仪需要全面升级**。朴素的SGD已无法应对LLM的训练。其演进体现在：
        1.  **优化器升级**：采用**自适应学习率优化器（如Adam, AdamW）**。它们为每个参数维护独立的学习率，能更平稳地处理不同参数尺度和稀疏梯度，是训练稳定的关键。
        2.  **动态调度**：引入复杂的学习率调度（如余弦退火、线性预热），在训练初期稳定，后期精细调优。
        3.  **稳定化技术**：梯度裁剪（Gradient Clipping）成为标配，防止异常梯度导致训练崩溃。
        4.  **并行化策略**：梯度下降的更新步骤必须与分布式并行策略协同设计。例如，在数据并行中，需要跨设备同步梯度；在模型并行中，参数更新本身也是分布式的。

---

### 模型损失函数 && 反向传播
在LLM的预训练阶段，最主流的损失函数是**因果语言建模（Causal Language Modeling）的交叉熵损失**，也称**下一个词元预测损失**。

给定一个文本序列 $ \mathbf{x} = (x_1, x_2, ..., x_T) $，模型将其编码为词元序列。在每一步 $ t $，模型基于之前的所有词元 $ x_{<t} $ 预测下一个词元 $ x_t $ 的概率分布 $ P_\theta(x_t | x_{<t}) $。损失函数是每一步预测的负对数似然之和的平均：
$$
L(\theta) = -\frac{1}{T} \sum_{t=1}^{T} \log P_\theta(x_t | x_{<t})
$$
其核心是衡量模型预测的分布与真实“one-hot”分布（真实的下一个词元）之间的差异。

**LLM反向传播的特点**：
1.  **序列化的计算图**：由于自回归特性，第 $ t $ 步的计算依赖于前 $ t-1 $ 步的所有中间激活值。这导致了巨大的**内存开销（激活值存储）**，成为训练的主要瓶颈之一。技术如**激活重计算（Activation Checkpointing）** 被广泛使用，即在前向传播时只存储部分层的激活值，在反向传播时临时重算其余部分，以时间换空间。
2.  **注意力机制的梯度流**：Transformer中的自注意力机制引入了所有词元对之间的交互。反向传播时需要计算损失对每个注意力权重和中间表示的梯度，这部分计算量巨大，但也是模型学习长程依赖的关键。
3.  **分布式反向传播**：在模型并行（如Tensor Parallelism）下，单个层的计算被分割到多个设备上。反向传播需要精心设计通信操作，以确保跨设备的梯度能够被正确聚合和同步，这通常由深度学习框架（如PyTorch的`FSDP`、Megatron-LM）在底层自动管理。

---

### 梯度下降更新权重
LLM训练中，权重更新不再是小规模网络中的简单步骤，而是一个集成了多种技术的复杂过程。

1.  **优化器：AdamW**

2.  **关键训练技术**：
    *   **混合精度训练**：使用FP16/BF16进行前向和反向传播以加速计算、节省内存，同时保留FP32的权重主副本用于更新，以保持数值稳定性。
    *   **梯度裁剪**：在反向传播后、优化器更新前，将梯度向量的范数限制在一个阈值内，防止训练因梯度爆炸而失效。
    *   **学习率调度**：采用“预热+衰减”策略。训练初期进行数千步的**线性预热**，让学习率从0缓慢增至峰值，使优化初期更稳定。之后采用**余弦衰减**等方式缓慢降低学习率，帮助模型收敛到更优的极小点。

3.  **批大小（Batch Size）的宏观策略**：
    LLM训练通常使用极大的**全局批大小**（Global Batch Size），可能是数百万个词元。这是通过**数据并行**将大批量分割到成千上万个GPU上实现的。增大批大小可以更准确地估计梯度方向，从而允许使用更高的学习率，理论上能加快收敛。但批大小与学习率、模型大小之间存在复杂的权衡关系，需要根据经验法则（如“√倍批大小，√倍学习率”）和大量实验来确定最优配置。

---
